datasets:
  train:
    human:
      fasta: /mnt/project/marquet/Variants/VespaG/Fasta/rr/up_humvsmarksafm.fasta
      embeddings:
        prott5: data/train_v2/human/prott5_embeddings.h5
        esm2: data/train_v2/human/esm2_embeddings.h5
      gemme_archive: data/train_v2/zipped/human_fasta.tar.gz
      splits:
        train: data/train_v2/human/splits/train_full.csv
        val: data/train_v2/human/splits/val_full.csv
    droso:
      fasta: /mnt/project/marquet/Variants/VespaG/Fasta/rr/up_drosovsmarksafm.fasta
      embeddings:
        prott5: data/train_v2/droso/prott5_embeddings.h5
        esm2: data/train_v2/droso/esm2_embeddings.h5
      gemme_archive: data/train_v2/zipped/droso_fasta.tar.gz
      splits:
        train: data/train_v2/droso/splits/train_full.csv
        val: data/train_v2/droso/splits/val_full.csv
    ecoli:
      fasta: /mnt/project/marquet/Variants/VespaG/Fasta/rr/up_ecolivsmarksafm.fasta
      embeddings:
        prott5: data/train_v2/ecoli/prott5_embeddings.h5
        esm2: data/train_v2/ecoli/esm2_embeddings.h5
      gemme_archive: data/train_v2/zipped/ecoli_fasta.tar.gz
      splits:
        train: data/train_v2/ecoli/splits/train_full.csv
        val: data/train_v2/ecoli/splits/val_full.csv
    virus:
      fasta: /mnt/project/marquet/Variants/VespaG/Fasta/rr/up_virusvsmarksafm.fasta
      #fasta: data/train_v2/virus/virus_with_truncated_shallow_seqs.fasta
      embeddings:
        prott5: data/train_v2/virus/backup/prott5_embeddings.h5
        esm2: data/train_v2/virus/backup/esm2_embeddings.h5
      gemme_archive: data/train_v2/zipped/virus_fasta.tar.gz
      splits:
        train: data/train_v2/virus/backup/splits/train_full.csv
        val: data/train_v2/virus/backup/splits/val_full.csv
    all:
      fasta: /mnt/project/marquet/Variants/VespaG/Fasta/rr/up_allvsmarksafm.fasta
      embeddings:
        prott5: data/train_v2/all/prott5_embeddings.h5
        esm2: data/train_v2/all/esm2_embeddings.h5
      gemme_archive: data/train_v2/zipped/all_fasta.tar.gz
      splits:
        full: data/train_v2/all/splits/full.csv
        train: data/train_v2/all/splits/train_full.csv
        val: data/train_v2/all/splits/val_full.csv
  test:
    mega_dataset:
      fasta: data/test/mega_dataset/dataset3_unique_sequences.fasta
    mega_dataset_v1_rasp:
      fasta: data/test/mega_dataset_v1_rasp/rasp_unique_sequences.fasta
    proteingym_substitutions:
      fasta: data/test/proteingym_substitutions/unique_proteins.fasta
    alphams:
      fasta: data/test/alphams_maves/AM_MAVE.fasta

gemme:
  alphabet: "ACDEFGHIKLMNPQRSTVWY"
  prediction_gzip: "/mnt/project/schlensok/VESPA2/new_gemme_preds.tar.gz"

random:
  seed: 42

preprocessing:
  na_threshold: .5

splits:
  validation_size: 0.2

training:
  single_taxon:
    sampling_strategy: basic
  all_taxa:
    sampling_strategy: basic

eval:
  batch_size: 8192
  proteingym:
    reference_files:
      per_protein: /mnt/project/schlensok/VESPA2/ProteinGym/MSA_Files_Elodie/neffTab_full.csv
      per_dms: data/test/proteingym_substitutions/reference.csv
    dms_directory: /mnt/project/schlensok/VESPA2/ProteinGym/ProteinGym_substitutions/

models:
  fnn:
    architecture: fnn
    model_parameters:
      hidden_dims: [256, 64]
      dropout_rate: 0.2
    training_parameters:
      learning_rate: 0.0001
      batch_size:
        training: 25000
        validation: 8192
      epochs: 200
      val_every_epoch: 1
      checkpoint_every_epoch: ~

  fnn_1_layer:
    architecture: fnn
    model_parameters:
      hidden_dims: [256]
      dropout_rate: 0.2
    training_parameters:
      learning_rate: 0.0001
      batch_size:
        training: 25000
        validation: 8192
      epochs: 200
      val_every_epoch: 1
      checkpoint_every_epoch: ~

  linreg:
    architecture: fnn
    model_parameters:
      hidden_dims: []
      dropout_rate: 0.2
    training_parameters:
      learning_rate: 0.0001
      batch_size:
        training: 25000
        validation: 8192
      epochs: 200
      val_every_epoch: 1
      checkpoint_every_epoch: ~

  cnn:
    architecture: cnn
    model_parameters:
      n_channels: 256
      kernel_size: 7
      padding: 3
      fully_connected_layers: [ 256, 64 ]
      dropout:
        fnn: 0.2
        cnn: 0.2
    training_parameters:
      learning_rate: 0.0001
      batch_size:
        training: 25000
        validation: 8192
      epochs: 200
      val_every_epoch: 1
      checkpoint_every_epoch: ~
